import asyncio
import os
from dotenv import load_dotenv
from engine import BenchmarkEngine

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

async def main():
    print("ğŸš€ å¼€å§‹è¿è¡Œå¤šæœåŠ¡å•†åŸºå‡†æµ‹è¯•...")
    engine = BenchmarkEngine()

    # å®šä¹‰æµ‹è¯•é…ç½®
    # å…³é”®ä¿®æ­£ï¼šå¯¹äºå…¼å®¹ OpenAI æ¥å£çš„æœåŠ¡å•†ï¼ˆè‡ªå®šä¹‰ BaseURLï¼‰ï¼Œ
    # Litellm è¦æ±‚æ¨¡å‹åç§°å¿…é¡»ä»¥ 'openai/' å¼€å¤´ï¼Œ
    # è¿™æ ·å®ƒæ‰çŸ¥é“è¦ç”¨ OpenAI çš„åè®®æ ¼å¼å»æ„é€  HTTP è¯·æ±‚ã€‚
    test_configs = [
        # ç¡…åŸºæµåŠ¨
        {
            "provider": "SiliconFlow",
            "model": "openai/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
            "api_key": os.getenv("SILICONFLOW_API_KEY"),
            "api_base": os.getenv("SILICONFLOW_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # é˜¿é‡Œäº‘
        {
            "provider": "Aliyun",
            "model": "openai/deepseek-v3", 
            "api_key": os.getenv("ALIYUN_API_KEY"),
            "api_base": os.getenv("ALIYUN_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # Gitee
        {
            "provider": "Gitee", 
            "model": "openai/DeepSeek-V3", 
            "api_key": os.getenv("GITEE_API_KEY"),
            "api_base": os.getenv("GITEE_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # PPIO
        {
            "provider": "PPIO",
            "model": "openai/deepseek/deepseek-v3/community",
            "api_key": os.getenv("PPIO_API_KEY"),
            "api_base": os.getenv("PPIO_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # æ— é—®è‹ç©¹ (Infini)
        {
            "provider": "Infini",
            "model": "openai/deepseek-v3", 
            "api_key": os.getenv("INFINI_API_KEY"),
            "api_base": os.getenv("INFINI_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # ä¸ƒç‰›äº‘ (Qiniu)
        {
            "provider": "Qiniu",
            "model": "openai/deepseek-v3", 
            "api_key": os.getenv("QINIU_API_KEY"),
            "api_base": os.getenv("QINIU_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # å¹¶è¡Œæ™ºç®—äº‘ (Paratera)
        # ä¿®æ­£ï¼šæ ¹æ®æŠ¥é”™ä¿¡æ¯ï¼ŒParatera éœ€è¦ä½¿ç”¨ç‰¹å®šçš„ç‰ˆæœ¬å·åç§° 'DeepSeek-V3-250324'
        {
            "provider": "Paratera",
            "model": "openai/DeepSeek-V3-250324", 
            "api_key": os.getenv("PARATERA_API_KEY"),
            "api_base": os.getenv("PARATERA_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # åŸºçŸ³æ™ºç®— (CoresHub)
        # ä¿®æ­£ï¼šå»é™¤ 'deepseek-ai/' å‰ç¼€ï¼Œå°è¯•ç›´æ¥ç”¨ 'DeepSeek-V3'
        {
            "provider": "CoresHub",
            "model": "openai/DeepSeek-V3", 
            "api_key": os.getenv("CORESHUB_API_KEY"),
            "api_base": os.getenv("CORESHUB_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # UCLOUD
        # ä¿®æ­£ï¼šModelVerse åˆ—è¡¨æ˜¾ç¤ºä¸º specific version 'deepseek-ai/DeepSeek-V3-0324'
        {
            "provider": "UCLOUD",
            "model": "openai/deepseek-ai/DeepSeek-V3-0324", 
            "api_key": os.getenv("UCLOUD_API_KEY"),
            "api_base": os.getenv("UCLOUD_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # ç«å±±æ–¹èˆŸ (éœ€è¦æ›¿æ¢ä¸ºå…·ä½“çš„ Endpoint ID)
        {
            "provider": "Volcengine",
            "model": "openai/doubao-seed-1-8-251228", # ğŸ”´ è¯·åœ¨æ­¤å¤„å¡«å…¥æ‚¨åœ¨ç«å±±å¼•æ“æ§åˆ¶å°åˆ›å»ºçš„æ¥å…¥ç‚¹ID
            "api_key": os.getenv("VOLCENGINE_API_KEY"),
            "api_base": os.getenv("VOLCENGINE_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # å¿«æ‰‹ä¸‡æ“
        {
            "provider": "Kwai",
            "model": "openai/deepseek-v3",
            "api_key": os.getenv("KWAI_API_KEY"),
            "api_base": os.getenv("KWAI_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # æ™ºè°±AI (GLM-4)
        {
            "provider": "Zhipu",
            "model": "openai/glm-4", 
            "api_key": os.getenv("ZHIPU_API_KEY"),
            "api_base": os.getenv("ZHIPU_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # è…¾è®¯äº‘
        {
            "provider": "Tencent",
            "model": "openai/deepseek-v3",
            "api_key": os.getenv("TENCENT_API_KEY"),
            "api_base": os.getenv("TENCENT_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # é›¶å…‹äº‘ 
        {
            "provider": "LinkAI",
            "model": "openai/DeepSeek-V3.2",
            "api_key": os.getenv("LINKAI_API_KEY"),
            "api_base": os.getenv("LINKAI_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # å¤©ç¿¼äº‘
        {
            "provider": "CTyun",
            "model": "openai/DeepSeek-R1-æ˜‡è…¾ç‰ˆ", # å°è¯•ä¿®æ­£ä¸ºå°å†™ id
            "api_key": os.getenv("CTYUN_API_KEY"),
            "api_base": os.getenv("CTYUN_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # MoonShot
        {
            "provider": "MoonShot",
            "model": "openai/moonshot-v1-8k",
            "api_key": os.getenv("MOONSHOT_API_KEY"),
            "api_base": os.getenv("MOONSHOT_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # ç™¾çµå¤§æ¨¡å‹ (æš‚åœæµ‹è¯•ï¼šéœ€å¼€é€šæœåŠ¡)
        {
            "provider": "Bailing",
            "model": "openai/Ling-1T",
            "api_key": os.getenv("BAILING_API_KEY"),
            "api_base": os.getenv("BAILING_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # é˜¶è·ƒæ˜Ÿè¾°
        {
            "provider": "StepFun",
            "model": "openai/step-1-8k",
            "api_key": os.getenv("STEPFUN_API_KEY"),
            "api_base": os.getenv("STEPFUN_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # DeepSeek
        {
            "provider": "DeepSeek",
            "model": "openai/deepseek-chat",
            "api_key": os.getenv("DEEPSEEK_API_KEY"),
            "api_base": os.getenv("DEEPSEEK_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        },
        # SCNet
        {
            "provider": "SCNet",
            "model": "openai/Qwen3-235B-A22B", # å°è¯•ä¿®æ­£ä¸ºå°å†™ id
            "api_key": os.getenv("SCNET_API_KEY"),
            "api_base": os.getenv("SCNET_API_BASE"),
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        }
    ]

    print(f"\nğŸ“‹ æµ‹è¯•åˆ—è¡¨ ({len(test_configs)} ä¸ªæœåŠ¡å•†):")
    for cfg in test_configs:
        print(f"  - [{cfg['provider']}] æ¨¡å‹: {cfg['model']}")

    print("\nâ³ æ­£åœ¨å¹¶è¡Œå‘é€è¯·æ±‚...\n")
    
    # è¿è¡Œæµ‹è¯•
    results = await engine.run_batch(test_configs)

    # æ‰“å°ç»“æœè¡¨æ ¼
    print(f"{'æœåŠ¡å•†':<12} | {'æ¨¡å‹':<30} | {'çŠ¶æ€':<8} | {'é¦–å­—å»¶è¿Ÿ':<10} | {'ååé‡':<10} | {'ä»·æ ¼($/M)'}")
    print("-" * 100)

    for r in results:
        status_icon = "âœ…" if r['status'] == 'success' else "âŒ"
        # æˆªæ–­è¿‡é•¿çš„æ¨¡å‹åä»¥é€‚åº”è¡¨æ ¼
        model_display = (r['model'][:28] + '..') if len(r['model']) > 28 else r['model']
        
        cost_display = f"{r.get('cost', 0):.6f}"
        
        print(f"{r['provider']:<12} | {model_display:<30} | {status_icon} {r['status']:<5} | {r.get('latency_ttft', 0):<10.4f} | {r.get('throughput', 0):<10.2f} | {cost_display}")

        if r['status'] == 'error':
            print(f"  â””â”€ é”™è¯¯ä¿¡æ¯: {r.get('error')}")

if __name__ == "__main__":
    asyncio.run(main())
